{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabular Classifier with auto Deep Learning\n",
    "This solution will evaluate between several deep learning models of various architectures  on the user provided data. It will identify the best performing deep learning model architecture  on the basis of validation metric for tabular classification. This will reduce the  time and effort for the model building task for a data scientist. This solution automates several of deep learning tasks in data science.\n",
    "\n",
    "### Contents\n",
    "\n",
    "1. [Set up the environment](#Set-up-the-environment)\n",
    "1. [Usage Instructions](#Usage-Instructions)\n",
    "1. [Upload the data for training](#Upload-the-data-for-training)\n",
    "1. [Run Training Job](#Run-Training-Job)\n",
    "1. [Live Inference Endpoint](#Live Inference)\n",
    "1. [Batch Transform Job](#Batch-Transform-Job)\n",
    "1. [Output Interpretation](#Output-Interpretation)\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/Flow_diagram.JPG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "To run this algorithm you need to have access to the following AWS Services:\n",
    "- Access to AWS SageMaker and the model package.\n",
    "- An S3 bucket to specify input/output.\n",
    "- Role for AWS SageMaker to access input/output from S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input format\n",
    "#### Input:\n",
    "Name of the file: <b>train.csv</b><br>\n",
    "This file contains historical incidents that have been resolved. The solution uses the following incident specific inputs to derive specific productivity measures such as efficiency, experience and workload management across incident types for incident managers to make the predictions.<br><br>\n",
    "\n",
    "</ul>\n",
    "<li>  ID: Unique identifier for the request- alphanumeric e.g. INC0001029696</li>\n",
    "<li> Reported_Day: The day of the week in number (Preferred format: 1-7)</li>\n",
    "\n",
    "<li> prod_cat: First level category for requests e.g. Miscellaneous_Instance_Database_SQL Server Database</li>\n",
    "<li> Country: Country of origin of request, Preferred format: USA)</li>\n",
    "<li> Detailed_Description: Free Text Describing the problem in users works</li>\n",
    "<li> Priority: Status of the request e.g. Low/Medium/High</li>\n",
    "<li> Impact: High/Medium/Low\n",
    "</ul><br>\n",
    "NOTE:\n",
    "</ul>\n",
    "<li>Not all requests are mandatory. Optional Fields :Prod_Cat, Detailed_Description,prod_cat</li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "Here we specify a bucket to use and the role that will be used for working with SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "prefix = 'tabular-classifier'\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the session\n",
    "The session remembers our connection parameters to SageMaker. We'll use it to perform all of our SageMaker operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload the data for training\n",
    "When training large models with huge amounts of data, you'll typically use big data tools, like Amazon Athena, AWS Glue, or Amazon EMR, to create your data in S3. For the purposes of this example, we're using classification dataset, which we have included.\n",
    "\n",
    "We can use use the tools provided by the SageMaker Python SDK to upload the data to a default bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://mphasis-marketplace/tabular_data/input/sample_train_data.zip'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location= 's3://mphasis-marketplace/tabular_data/input/sample_train_data.zip'\n",
    "data_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an estimator and fit the model\n",
    "In order to use SageMaker to fit our algorithm, we'll create an Estimator that defines how to use the container to train. This includes the configuration we need to invoke SageMaker training:\n",
    "- The container name. This is constructed as in the shell commands above.\n",
    "- The role. As defined above.\n",
    "- The instance count which is the number of machines to use for training.\n",
    "- The instance type which is the type of machine to use for training.\n",
    "- The output path determines where the model artifact will be written.\n",
    "- The session is the SageMaker session object that we defined above\n",
    "\n",
    "Then we use fit() on the estimator to train against the data that we uploaded above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-24 14:35:57 Starting - Starting the training job...\n",
      "2021-03-24 14:36:21 Starting - Launching requested ML instancesProfilerReport-1616596557: InProgress\n",
      "......\n",
      "2021-03-24 14:37:22 Starting - Preparing the instances for training......\n",
      "2021-03-24 14:38:26 Downloading - Downloading input data...\n",
      "2021-03-24 14:38:42 Training - Downloading the training image......\n",
      "2021-03-24 14:39:52 Training - Training image download completed. Training in progress.\u001b[34m2021-03-24 14:39:48.480924: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:48.480958: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.248668: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.250500: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.250520: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.250538: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-87-153.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.251334: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.355541: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:53.361331: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900090000 Hz\n",
      "\u001b[0m\n",
      "\u001b[34mSearch: Running Trial #1\n",
      "\u001b[0m\n",
      "\u001b[34mHyperparameter    |Value             |Best Value So Far \u001b[0m\n",
      "\u001b[34mstructured_data...|False             |?                 \u001b[0m\n",
      "\u001b[34mstructured_data...|False             |?                 \u001b[0m\n",
      "\u001b[34mstructured_data...|2                 |?                 \u001b[0m\n",
      "\u001b[34mstructured_data...|32                |?                 \u001b[0m\n",
      "\u001b[34mstructured_data...|0                 |?                 \u001b[0m\n",
      "\u001b[34mstructured_data...|32                |?                 \u001b[0m\n",
      "\u001b[34mclassification_...|0                 |?                 \u001b[0m\n",
      "\u001b[34moptimizer         |adam              |?                 \u001b[0m\n",
      "\u001b[34mlearning_rate     |0.001             |?                 \n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:53.070594: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:53.070642: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 7s - loss: 2.5690 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 1s 22ms/step - loss: 1.4173 - accuracy: 0.6502 - val_loss: 0.7238 - val_accuracy: 0.5913\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 0.6631 - accuracy: 0.5938#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.7759 - accuracy: 0.5824 - val_loss: 0.5676 - val_accuracy: 0.7304\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 0.7423 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.7004 - accuracy: 0.6296 - val_loss: 0.6268 - val_accuracy: 0.7130\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 0.8923 - accuracy: 0.4688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.7273 - accuracy: 0.6122 - val_loss: 0.5793 - val_accuracy: 0.7217\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 0.7386 - accuracy: 0.5000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.6703 - accuracy: 0.6100 - val_loss: 0.5380 - val_accuracy: 0.7391\n",
      "\u001b[0m\n",
      "\u001b[34mTrial 1 Complete [00h 00m 01s]\u001b[0m\n",
      "\u001b[34mval_loss: 0.5380064845085144\n",
      "\u001b[0m\n",
      "\u001b[34mBest val_loss So Far: 0.5380064845085144\u001b[0m\n",
      "\u001b[34mTotal elapsed time: 00h 00m 01s\n",
      "\u001b[0m\n",
      "\u001b[34mSearch: Running Trial #2\n",
      "\u001b[0m\n",
      "\u001b[34mHyperparameter    |Value             |Best Value So Far \u001b[0m\n",
      "\u001b[34mstructured_data...|False             |False             \u001b[0m\n",
      "\u001b[34mstructured_data...|False             |False             \u001b[0m\n",
      "\u001b[34mstructured_data...|2                 |2                 \u001b[0m\n",
      "\u001b[34mstructured_data...|32                |32                \u001b[0m\n",
      "\u001b[34mstructured_data...|0.5               |0                 \u001b[0m\n",
      "\u001b[34mstructured_data...|32                |32                \u001b[0m\n",
      "\u001b[34mclassification_...|0                 |0                 \u001b[0m\n",
      "\u001b[34moptimizer         |adam              |adam              \u001b[0m\n",
      "\u001b[34mlearning_rate     |0.001             |0.001             \n",
      "\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:53.500384: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:53.500425: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 6s - loss: 3.6003 - accuracy: 0.5000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 1s 10ms/step - loss: 3.5915 - accuracy: 0.4986 - val_loss: 0.6278 - val_accuracy: 0.6609\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 3.5866 - accuracy: 0.4688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 3.1510 - accuracy: 0.5119 - val_loss: 0.5403 - val_accuracy: 0.6957\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 1.6411 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 2.0748 - accuracy: 0.5717 - val_loss: 0.5086 - val_accuracy: 0.7652\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 1.3540 - accuracy: 0.6250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 2.0145 - accuracy: 0.5426 - val_loss: 0.5089 - val_accuracy: 0.7478\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m#015 1/16 [>.............................] - ETA: 0s - loss: 1.4901 - accuracy: 0.6250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 1.8621 - accuracy: 0.5783 - val_loss: 0.5169 - val_accuracy: 0.7217\n",
      "\u001b[0m\n",
      "\u001b[34mTrial 2 Complete [00h 00m 01s]\u001b[0m\n",
      "\u001b[34mval_loss: 0.5086356401443481\n",
      "\u001b[0m\n",
      "\u001b[34mBest val_loss So Far: 0.5086356401443481\u001b[0m\n",
      "\u001b[34mTotal elapsed time: 00h 00m 03s\u001b[0m\n",
      "\u001b[35mStarting the training.\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.433315: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.435279: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.435300: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.435321: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-71-244.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.436135: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.537409: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[35m2021-03-24 14:39:57.542574: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900100000 Hz\u001b[0m\n",
      "\u001b[34mEpoch 1/5\u001b[0m\n",
      "\u001b[34m#015 1/20 [>.............................] - ETA: 7s - loss: 9.2280 - accuracy: 0.4375#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 6.6112 - accuracy: 0.4321\u001b[0m\n",
      "\u001b[34mEpoch 2/5\u001b[0m\n",
      "\u001b[34m#015 1/20 [>.............................] - ETA: 0s - loss: 3.6269 - accuracy: 0.4375#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 3.9125 - accuracy: 0.4873\u001b[0m\n",
      "\u001b[34mEpoch 3/5\u001b[0m\n",
      "\u001b[34m#015 1/20 [>.............................] - ETA: 0s - loss: 3.7015 - accuracy: 0.5000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 3.2517 - accuracy: 0.4977\u001b[0m\n",
      "\u001b[34mEpoch 4/5\u001b[0m\n",
      "\u001b[34m#015 1/20 [>.............................] - ETA: 0s - loss: 4.3945 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 3.4934 - accuracy: 0.5196\u001b[0m\n",
      "\u001b[34mEpoch 5/5\u001b[0m\n",
      "\u001b[34m#015 1/20 [>.............................] - ETA: 0s - loss: 3.5141 - accuracy: 0.4688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 3.2111 - accuracy: 0.5064\u001b[0m\n",
      "\u001b[32mStarting the training.\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.440369: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.442399: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.442420: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.442442: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-10-0-117-52.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.443308: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[35mSearch: Running Trial #1\n",
      "\u001b[0m\n",
      "\u001b[35mHyperparameter    |Value             |Best Value So Far \u001b[0m\n",
      "\u001b[35mstructured_data...|False             |?                 \u001b[0m\n",
      "\u001b[35mstructured_data...|False             |?                 \u001b[0m\n",
      "\u001b[35mstructured_data...|2                 |?                 \u001b[0m\n",
      "\u001b[35mstructured_data...|32                |?                 \u001b[0m\n",
      "\u001b[35mstructured_data...|0                 |?                 \u001b[0m\n",
      "\u001b[35mstructured_data...|64                |?                 \u001b[0m\n",
      "\u001b[35mclassification_...|0                 |?                 \u001b[0m\n",
      "\u001b[35moptimizer         |adam              |?                 \u001b[0m\n",
      "\u001b[35mlearning_rate     |0.001             |?                 \n",
      "\u001b[0m\n",
      "\u001b[35mEpoch 1/5\u001b[0m\n",
      "\u001b[34m2021-03-24 14:39:58.461030: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.546474: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[32m2021-03-24 14:39:58.551821: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2900090000 Hz\n",
      "\u001b[0m\n",
      "\u001b[32mSearch: Running Trial #1\n",
      "\u001b[0m\n",
      "\u001b[32mHyperparameter    |Value             |Best Value So Far \u001b[0m\n",
      "\u001b[32mstructured_data...|True              |?                 \u001b[0m\n",
      "\u001b[32mstructured_data...|False             |?                 \u001b[0m\n",
      "\u001b[32mstructured_data...|2                 |?                 \u001b[0m\n",
      "\u001b[32mstructured_data...|32                |?                 \u001b[0m\n",
      "\u001b[32mstructured_data...|0                 |?                 \u001b[0m\n",
      "\u001b[32mstructured_data...|32                |?                 \u001b[0m\n",
      "\u001b[32mclassification_...|0                 |?                 \u001b[0m\n",
      "\u001b[32moptimizer         |adam              |?                 \u001b[0m\n",
      "\u001b[32mlearning_rate     |0.001             |?                 \n",
      "\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 7s - loss: 1.4618 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 1s 22ms/step - loss: 0.9085 - accuracy: 0.6374 - val_loss: 0.5843 - val_accuracy: 0.6609\u001b[0m\n",
      "\u001b[35mEpoch 2/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.8108 - accuracy: 0.4688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.7042 - accuracy: 0.5809 - val_loss: 0.6077 - val_accuracy: 0.7043\u001b[0m\n",
      "\u001b[35mEpoch 3/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.9113 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.7341 - accuracy: 0.5740 - val_loss: 0.6180 - val_accuracy: 0.7043\u001b[0m\n",
      "\u001b[35mEpoch 4/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.8755 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.7203 - accuracy: 0.5798 - val_loss: 0.5917 - val_accuracy: 0.7130\u001b[0m\n",
      "\u001b[35mEpoch 5/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.8021 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.5915 - val_loss: 0.5807 - val_accuracy: 0.7043\n",
      "\u001b[0m\n",
      "\u001b[35mTrial 1 Complete [00h 00m 01s]\u001b[0m\n",
      "\u001b[35mval_loss: 0.5807287096977234\n",
      "\u001b[0m\n",
      "\u001b[35mBest val_loss So Far: 0.5807287096977234\u001b[0m\n",
      "\u001b[35mTotal elapsed time: 00h 00m 01s\n",
      "\u001b[0m\n",
      "\u001b[35mSearch: Running Trial #2\n",
      "\u001b[0m\n",
      "\u001b[35mHyperparameter    |Value             |Best Value So Far \u001b[0m\n",
      "\u001b[35mstructured_data...|False             |False             \u001b[0m\n",
      "\u001b[35mstructured_data...|False             |False             \u001b[0m\n",
      "\u001b[35mstructured_data...|2                 |2                 \u001b[0m\n",
      "\u001b[35mstructured_data...|32                |32                \u001b[0m\n",
      "\u001b[35mstructured_data...|0                 |0                 \u001b[0m\n",
      "\u001b[35mstructured_data...|1024              |64                \u001b[0m\n",
      "\u001b[35mclassification_...|0                 |0                 \u001b[0m\n",
      "\u001b[35moptimizer         |adam              |adam              \u001b[0m\n",
      "\u001b[35mlearning_rate     |0.001             |0.001             \n",
      "\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc70c33dca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc70c33d310> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc70c4bae50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[32mEpoch 1/5\u001b[0m\n",
      "\u001b[35mEpoch 1/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 8s - loss: 0.7578 - accuracy: 0.4375#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 1s 23ms/step - loss: 0.7036 - accuracy: 0.5518 - val_loss: 0.6473 - val_accuracy: 0.6957\u001b[0m\n",
      "\u001b[32mEpoch 2/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.6862 - accuracy: 0.5000#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6700 - val_loss: 0.5742 - val_accuracy: 0.7652\u001b[0m\n",
      "\u001b[32mEpoch 3/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.6385 - accuracy: 0.6250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.5836 - accuracy: 0.7350 - val_loss: 0.5180 - val_accuracy: 0.8435\u001b[0m\n",
      "\u001b[32mEpoch 4/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.5964 - accuracy: 0.7500#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8077 - val_loss: 0.4745 - val_accuracy: 0.8609\u001b[0m\n",
      "\u001b[32mEpoch 5/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.5574 - accuracy: 0.7500#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.8046 - val_loss: 0.4413 - val_accuracy: 0.8435\n",
      "\u001b[0m\n",
      "\u001b[32mTrial 1 Complete [00h 00m 01s]\u001b[0m\n",
      "\u001b[32mval_loss: 0.44128963351249695\n",
      "\u001b[0m\n",
      "\u001b[32mBest val_loss So Far: 0.44128963351249695\u001b[0m\n",
      "\u001b[32mTotal elapsed time: 00h 00m 01s\n",
      "\u001b[0m\n",
      "\u001b[32mSearch: Running Trial #2\n",
      "\u001b[0m\n",
      "\u001b[32mHyperparameter    |Value             |Best Value So Far \u001b[0m\n",
      "\u001b[32mstructured_data...|True              |True              \u001b[0m\n",
      "\u001b[32mstructured_data...|False             |False             \u001b[0m\n",
      "\u001b[32mstructured_data...|3                 |2                 \u001b[0m\n",
      "\u001b[32mstructured_data...|32                |32                \u001b[0m\n",
      "\u001b[32mstructured_data...|0                 |0                 \u001b[0m\n",
      "\u001b[32mstructured_data...|32                |32                \u001b[0m\n",
      "\u001b[32mclassification_...|0                 |0                 \u001b[0m\n",
      "\u001b[32moptimizer         |adam              |adam              \u001b[0m\n",
      "\u001b[32mlearning_rate     |0.001             |0.001             \n",
      "\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 6s - loss: 1.8598 - accuracy: 0.4688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 1s 11ms/step - loss: 1.2177 - accuracy: 0.6122 - val_loss: 0.6353 - val_accuracy: 0.7304\u001b[0m\n",
      "\u001b[35mEpoch 2/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 1.1545 - accuracy: 0.4688#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 4ms/step - loss: 0.8136 - accuracy: 0.6215 - val_loss: 0.6089 - val_accuracy: 0.6783\u001b[0m\n",
      "\u001b[35mEpoch 3/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.7375 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.6402 - accuracy: 0.6500 - val_loss: 0.6156 - val_accuracy: 0.7304\u001b[0m\n",
      "\u001b[35mEpoch 4/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.6511 - accuracy: 0.6875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 4ms/step - loss: 0.6655 - accuracy: 0.6533 - val_loss: 0.5276 - val_accuracy: 0.7391\u001b[0m\n",
      "\u001b[35mEpoch 5/5\u001b[0m\n",
      "\u001b[35m#015 1/16 [>.............................] - ETA: 0s - loss: 0.7224 - accuracy: 0.5938#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.6737 - accuracy: 0.6808 - val_loss: 0.5186 - val_accuracy: 0.7565\n",
      "\u001b[0m\n",
      "\u001b[35mTrial 2 Complete [00h 00m 01s]\u001b[0m\n",
      "\u001b[35mval_loss: 0.5185953378677368\n",
      "\u001b[0m\n",
      "\u001b[35mBest val_loss So Far: 0.5185953378677368\u001b[0m\n",
      "\u001b[35mTotal elapsed time: 00h 00m 03s\u001b[0m\n",
      "\u001b[35mEpoch 1/5\u001b[0m\n",
      "\u001b[34mtraining completed\u001b[0m\n",
      "\u001b[32mEpoch 1/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 6s - loss: 0.6821 - accuracy: 0.6250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 1s 12ms/step - loss: 0.6701 - accuracy: 0.6401 - val_loss: 0.6085 - val_accuracy: 0.7652\u001b[0m\n",
      "\u001b[32mEpoch 2/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.6398 - accuracy: 0.6250#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7133 - val_loss: 0.5380 - val_accuracy: 0.8261\u001b[0m\n",
      "\u001b[32mEpoch 3/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.5960 - accuracy: 0.7188#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7583 - val_loss: 0.4713 - val_accuracy: 0.8174\u001b[0m\n",
      "\u001b[32mEpoch 4/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.5476 - accuracy: 0.6875#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 4ms/step - loss: 0.5078 - accuracy: 0.7582 - val_loss: 0.4224 - val_accuracy: 0.8522\u001b[0m\n",
      "\u001b[32mEpoch 5/5\u001b[0m\n",
      "\u001b[32m#015 1/16 [>.............................] - ETA: 0s - loss: 0.4990 - accuracy: 0.8125#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01516/16 [==============================] - 0s 4ms/step - loss: 0.4730 - accuracy: 0.8004 - val_loss: 0.3944 - val_accuracy: 0.8261\u001b[0m\n",
      "\u001b[35m#015 1/20 [>.............................] - ETA: 7s - loss: 0.8872 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 2ms/step - loss: 1.2673 - accuracy: 0.5377\u001b[0m\n",
      "\u001b[35mEpoch 2/5\u001b[0m\n",
      "\u001b[35m#015 1/20 [>.............................] - ETA: 0s - loss: 1.4065 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.9453 - accuracy: 0.6270\u001b[0m\n",
      "\u001b[35mEpoch 3/5\u001b[0m\n",
      "\u001b[35m#015 1/20 [>.............................] - ETA: 0s - loss: 0.8045 - accuracy: 0.5312#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.6641 - accuracy: 0.6652\u001b[0m\n",
      "\u001b[35mEpoch 4/5\u001b[0m\n",
      "\u001b[35m#015 1/20 [>.............................] - ETA: 0s - loss: 1.0614 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.8282 - accuracy: 0.6409\u001b[0m\n",
      "\u001b[35mEpoch 5/5\u001b[0m\n",
      "\u001b[35m#015 1/20 [>.............................] - ETA: 0s - loss: 0.6931 - accuracy: 0.5625#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.6253 - accuracy: 0.6892\u001b[0m\n",
      "\u001b[35m2021-03-24 14:40:02.718574: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[32mTrial 2 Complete [00h 00m 01s]\u001b[0m\n",
      "\u001b[32mval_loss: 0.39442065358161926\n",
      "\u001b[0m\n",
      "\u001b[32mBest val_loss So Far: 0.39442065358161926\u001b[0m\n",
      "\u001b[32mTotal elapsed time: 00h 00m 03s\u001b[0m\n",
      "\u001b[32mEpoch 1/5\u001b[0m\n",
      "\u001b[32m#015 1/20 [>.............................] - ETA: 8s - loss: 0.6919 - accuracy: 0.6562#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 2ms/step - loss: 0.6643 - accuracy: 0.6653\u001b[0m\n",
      "\u001b[32mEpoch 2/5\u001b[0m\n",
      "\u001b[32m#015 1/20 [>.............................] - ETA: 0s - loss: 0.6109 - accuracy: 0.7500#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.5798 - accuracy: 0.7946\u001b[0m\n",
      "\u001b[32mEpoch 3/5\u001b[0m\n",
      "\u001b[32m#015 1/20 [>.............................] - ETA: 0s - loss: 0.5327 - accuracy: 0.7500#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.5017 - accuracy: 0.8006\u001b[0m\n",
      "\u001b[32mEpoch 4/5\u001b[0m\n",
      "\u001b[32m#015 1/20 [>.............................] - ETA: 0s - loss: 0.4545 - accuracy: 0.8125#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 1ms/step - loss: 0.4517 - accuracy: 0.8107\u001b[0m\n",
      "\u001b[32mEpoch 5/5\u001b[0m\n",
      "\u001b[32m#015 1/20 [>.............................] - ETA: 0s - loss: 0.4162 - accuracy: 0.8125#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01520/20 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8181\u001b[0m\n",
      "\u001b[32m2021-03-24 14:40:04.218707: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f25a8095280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f25a8716ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f25a8716280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[35mtraining completed\u001b[0m\n",
      "\u001b[32mWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5c5f72fe50> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[32mWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5c5f721ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[32mWARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f5c5f702ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[32mtraining completed\u001b[0m\n",
      "\n",
      "2021-03-24 14:40:22 Uploading - Uploading generated training model\n",
      "2021-03-24 14:40:22 Completed - Training job completed\n",
      "Training seconds: 318\n",
      "Billable seconds: 318\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/tabular-data-f:latest'.format(account, region)\n",
    "tree = sage.estimator.Estimator(image,\n",
    "                       role, 3, 'ml.c4.2xlarge',\n",
    "                      output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "tree.fit(data_location)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hosting your model\n",
    "You can use a trained model to get real time predictions using HTTP endpoint. Follow these steps to walk you through the process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-03-24 14:40:42 Starting - Preparing the instances for training\n",
      "2021-03-24 14:40:42 Downloading - Downloading input data\n",
      "2021-03-24 14:40:42 Training - Training image download completed. Training in progress.\n",
      "2021-03-24 14:40:42 Uploading - Uploading generated training model\n",
      "2021-03-24 14:40:42 Completed - Training job completed\n"
     ]
    }
   ],
   "source": [
    "training_job_name = tree.latest_training_job.name\n",
    "attached_tree = sage.estimator.Estimator.attach(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Deploy the model\n",
    "Deploying the model to SageMaker hosting just requires a deploy call on the fitted model. This call takes an instance count, instance type, and optionally serializer and deserializer functions. These are used when the resulting predictor is created on the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = attached_tree.deploy(4, 'ml.m4.xlarge', serializer=csv_serializer,endpoint_name='tabular-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose some data and use it for a prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data  = 's3://mphasis-marketplace/tabular_data/input/sample_test_data.zip'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Please send a proper format file'\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output\n",
    "\n",
    "Output files contains column predicted Group, which has the predicted class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_output_folder = \"batch-transform-output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), transform_output_folder)\n",
    "\n",
    "transformer = tree.transformer(instance_count=1,\n",
    "                               instance_type='ml.m4.xlarge',\n",
    "                               output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".................................\n",
      "\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [13] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.908501: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.908558: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.958057: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.958199: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.105861: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.105933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.107622: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.107796: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.816228: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.816780: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.816890: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.817127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3f083103c317): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.818077: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:09.597391: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:09.598503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300080000 Hz\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe743430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe743280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe7a5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"POST /invocations HTTP/1.1\" 200 32 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-03-24T17:36:09.947:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [13] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[35mStarting the inference server with 4 workers.\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [13] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [13] [INFO] Listening at: unix:/tmp/gunicorn.sock (13)\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [13] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m[2021-03-24 17:36:00 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.908501: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.908558: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.958057: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:00.958199: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.105861: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.105933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.107622: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:01.107796: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[35m[2021-03-24 17:36:00 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:00.908501: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:00.908558: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:00.958057: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:00.958199: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:01.105861: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:01.105933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:01.107622: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:01.107796: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.816228: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:08.816228: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.816780: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:08.816780: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.816890: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.817127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3f083103c317): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:08.818077: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:08.816890: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:08.817127: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (3f083103c317): /proc/driver/nvidia/version does not exist\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:08.818077: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:09.597391: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[34m2021-03-24 17:36:09.598503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300080000 Hz\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe743430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe743280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe7a5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"POST /invocations HTTP/1.1\" 200 32 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:09.597391: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\u001b[0m\n",
      "\u001b[35m2021-03-24 17:36:09.598503: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300080000 Hz\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe743430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe743280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[35mWARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fefbe7a5550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [24/Mar/2021:17:36:09 +0000] \"POST /invocations HTTP/1.1\" 200 32 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2021-03-24T17:36:09.947:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Batch Transform output saved to s3://sagemaker-us-east-2-786796469737/batch-transform-output\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(test_data, content_type='application/zip')\n",
    "transformer.wait()\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Please send a proper format file'\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], \"sample_test.zip\")\n",
    "\n",
    "\n",
    "\n",
    "s3_client = sess.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sess.default_bucket(), Key = file_key)\n",
    "response_bytes = response['Body'].read()\n",
    "print(response_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Output\n",
    "Lets read results of above transform job from s3 files and print output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID,Reported_Day,prod_cat,Country,Priority,Impact,Incident_Type,Reported_Source,Predicted Group\n",
      "INC000014022289,3,prod_cat -1,Country-1,Low,4-Minor,Incident_Type-1,Phone,Target-7\n",
      "INC000014060316,2,prod_cat -1,Country-1,Low,1-Minor,Incident_Type-2,Phone,Target-4\n",
      "INC000013880496,3,prod_cat -2,Country-1,Low,2-Minor,Incident_Type-1,Phone,Target-4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s3_client = sess.boto_session.client('s3')\n",
    "s3_client.download_file(sess.default_bucket(), \"{}/test.csv.out\".format(transform_output_folder), '/tmp/test.csv.out')\n",
    "with open('/tmp/test.csv.out') as f:\n",
    "    results = f.readlines() \n",
    "##print(\"Transform results: \\n{}\".format(''.join(results)))\n",
    "string_final = ''.join(results)\n",
    "\n",
    "print(string_final)\n",
    "\n",
    "with open(\"Output.txt\", \"w\") as text_file:\n",
    "    text_file.write(string_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}